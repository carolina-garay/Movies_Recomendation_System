

# <h1 align=center> **PROYECTO INDIVIDUAL N¬∫1** </h1>
# <h1 align=center> **Carolina del Valle Garay** </h1>

# <h1 align=center>**`Machine Learning Operations (MLOps)`**</h1>

![MLops](assets/MLops.webp)

## ```Introducci√≥n```

¬°Hola a tod@s! Estoy emocionada de presentarles mi primer proyecto individual de [Henry](https://www.soyhenry.com/), un sistema de recomendaci√≥n de pel√≠culas. Este proyecto combina mi pasi√≥n por la Matem√°tica, la Programaci√≥n y el Cine, utilizando t√©cnicas de Ciencia de Datos y Machine Learning para ofrecer recomendaciones personalizadas.

Mi proyecto simula un ambiente de trabajo real en una _start-up_ que provee servicios de agregaci√≥n de plataformas de streaming. Aqu√≠ he desarrollado una API que permite consultar informaci√≥n detallada sobre pel√≠culas, actores y directores, as√≠ como obtener recomendaciones de pel√≠culas basadas en diversos criterios como g√©neros, slogans, actores principales y directores. El objetivo principal es ayudar a los usuarios a descubrir nuevas pel√≠culas que se alineen con sus gustos e intereses.

El sistema utiliza un enfoque de filtrado basado en contenido, donde se analiza el texto descriptivo de las pel√≠culas y se calcula la similitud entre ellas. Para ello, he aplicado t√©cnicas de procesamiento de lenguaje natural, como la vectorizaci√≥n TF-IDF, que transforma el texto en datos num√©ricos que pueden ser procesados por algoritmos de machine learning.

Adem√°s, el proyecto incluye una interfaz de usuario simple y amigable, donde se pueden hacer consultas espec√≠ficas, como la cantidad de pel√≠culas estrenadas en un mes determinado o el puntaje promedio de una pel√≠cula. Tambi√©n he incluido una secci√≥n para explorar el √©xito de actores y directores, midiendo su impacto en t√©rminos de retorno financiero.

Este proyecto no s√≥lo ha sido una excelente oportunidad para aplicar mis habilidades en programaci√≥n y an√°lisis de datos, sino que tambi√©n me ha permitido explorar la intersecci√≥n entre el entretenimiento y la tecnolog√≠a. Espero que lo encuentren interesante y √∫til, y estoy ansiosa por recibir sus comentarios y sugerencias para seguir mejorando. ¬°Gracias Henry por acompa√±arme en este viaje!



## :white_check_mark: ```Objetivo General```

- :pushpin: Implementar una API para acceso a datos y recomendaciones.

## :white_check_mark: ```Objetivos Espec√≠ficos ```

- :pushpin: Realizar un preprocesamiento de datos (ETL)
- :pushpin: Realizar un an√°lisis exploratorio de datos (EDA) 
- :pushpin: Crear endpoints de API que permitan consultas espec√≠ficas y recomendaciones de pel√≠culas


## üí°```Metodolog√≠a de trabajo```

Para llevar a cabo los objetivos, se ejecutaron los siguientes procedimientos utilizando diversas herramientas:

-  :one: <font color='green'>Google Drive: se utiliz√≥ la cuenta de quien les escribe para almacenar el conjunto de datos de los datasets, ambos conjuntos se descargaron en el notebook ETL_Garay.ipynb

- :two: <font color='green'>Visual Studio Code: se utiliz√≥ este editor de c√≥digo para crear un directorio con el nombre del proyecto y se implement√≥ un entorno virtual de forma local. En este entorno se procedi√≥ a crear la API junto a los end point ‚Äò/‚Äô.
- :three: <font color='green'>Google Colaboratory: Se utiliz√≥ esta plataforma para el desarrollo de los procesos ETL, EDA y Modelo de Machine Learning. 
    - **ETL:** se realiz√≥ limpieza y transformaci√≥n de los datos para garantizar la calidad y consistencia de la informaci√≥n utilizada en el sistema de recomendaci√≥n. El resultado del jupyter notebook (ETL_Garay.ipynb) desarrolado para esta etapa corresponde al conjunto de datos que se utiliz√≥ para alimentar a la Api, se lo descarg√≥ en formato parquet con el nombre  api_consult.parquet.
    - **EDA:** este an√°lisis se realiz√≥ con la finalidad de identificar patrones, tendencias y relaciones en los datos, as√≠ como detectar posibles outliers y anomal√≠as. Dicho an√°lisis posibilit√≥ decidir cu√°les atributos eran los adecuados para aplicar el Modelo de Machine Learning. El resultado del jupyter notebook (EDA_Garay.ipynb) desarrolado para esta etapa corresponde al conjunto de datos que se utiliz√≥ para aplicar el modelo seleccionado.
    - **Modelo de Machine Learning:** para el modelado se seleccionaron TF-IDF (Term Frequency-Inverse Document Frequency) y la similitud del coseno. Estas son dos t√©cnicas fundamentales que se utilizan en procesamiento de lenguaje natural (NLP) para medir la relevancia de t√©rminos en documentos y para calcular la similitud entre ellos. Los distintos modelos aplicados se encuentran en el notebook ML_Garay.ipynb

Todas las tareas realizadas se encuentran en la carpeta ETL_EDA_ML_Garay. Para ejecutar cada notebook se sugiere descargarlo y luego subir cada uno a Google Colaboratory.

- :four: <font color='green'>Github: se us√≥ esta plataforma para almacenar el proyecto. Se cre√≥ un repositori√≥ con el nombre **Movies_Recomendation_System**. Este paso es imprescindible para deployar la Api en render, dado que se utiliza la direcci√≥n del repositorio para realizar el deploy.

- :five: <font color='green'>Render: se utiliz√≥ este sitio para desplegar el proyecto. Primeramente se cre√≥ una cuenta en el sitio <p style="color: red;">Esta es una oraci√≥n coloreada en rojo.</p>


